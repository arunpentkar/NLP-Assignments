{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arunpentkar/NLP-Assignments/blob/main/Assingnment_06.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fz2iC5cpifFs",
        "outputId": "0c0a56af-c95e-4bf4-e192-07c35fec9952"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Parameters for data processing\n",
        "max_features = 20000  # Number of words to consider as features\n",
        "maxlen = 100  # Cut off reviews after 100 words\n",
        "\n",
        "# Load data from keras.datasets\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "\n",
        "# Pad sequences to ensure uniform length\n",
        "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = pad_sequences(x_test, maxlen=maxlen)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
        "\n",
        "# Parameters for the GRU model\n",
        "embedding_dim = 128\n",
        "gru_units = 64\n",
        "\n",
        "# Build the GRU model\n",
        "gru_model = Sequential()\n",
        "gru_model.add(Embedding(input_dim=max_features, output_dim=embedding_dim, input_length=maxlen))\n",
        "gru_model.add(GRU(gru_units, dropout=0.2, recurrent_dropout=0.2))\n",
        "gru_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "gru_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLdO4qw6imic",
        "outputId": "cafd2253-94fe-4c82-d943-d0178d47083e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the GRU model\n",
        "gru_history = gru_model.fit(x_train, y_train, batch_size=32, epochs=5, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHCiyJN5inQm",
        "outputId": "50422200-89e0-45ff-ce6b-1566a9c61377"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 95ms/step - accuracy: 0.6544 - loss: 24.7721 - val_accuracy: 0.6892 - val_loss: 0.5781\n",
            "Epoch 2/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 91ms/step - accuracy: 0.7777 - loss: 594.5159 - val_accuracy: 0.6904 - val_loss: 0.5825\n",
            "Epoch 3/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 93ms/step - accuracy: 0.8000 - loss: 0.4383 - val_accuracy: 0.6880 - val_loss: 0.5917\n",
            "Epoch 4/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 93ms/step - accuracy: 0.8353 - loss: 0.3843 - val_accuracy: 0.6886 - val_loss: 0.6084\n",
            "Epoch 5/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 98ms/step - accuracy: 0.8522 - loss: 0.3452 - val_accuracy: 0.6996 - val_loss: 0.6249\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def generate_text(seed_text, next_words=20):\n",
        "    # Get the word index dictionary from IMDB dataset\n",
        "    word_index = imdb.get_word_index()\n",
        "    reverse_word_index = {value: key for (key, value) in word_index.items()}\n",
        "\n",
        "    # Convert seed text to indices\n",
        "    tokenized_seq = [word_index.get(word, 0) for word in seed_text.lower().split()]\n",
        "    tokenized_seq = pad_sequences([tokenized_seq], maxlen=maxlen, padding='pre')\n",
        "\n",
        "    generated_text = seed_text\n",
        "\n",
        "    for _ in range(next_words):\n",
        "        # Predict next word probabilities\n",
        "        predicted_probs = gru_model.predict(tokenized_seq, verbose=0)\n",
        "        predicted_index = int(np.round(predicted_probs[0][0]))\n",
        "\n",
        "        # Get the predicted word\n",
        "        predicted_word = reverse_word_index.get(predicted_index, '?')\n",
        "        generated_text += ' ' + predicted_word\n",
        "\n",
        "        # Update the sequence for the next prediction\n",
        "        tokenized_seq = np.roll(tokenized_seq, -1)\n",
        "        tokenized_seq[0, -1] = predicted_index\n",
        "\n",
        "    return generated_text\n",
        "\n",
        "# Example usage\n",
        "seed_text = \"the movie was\"\n",
        "generated_text = generate_text(seed_text, next_words=20)\n",
        "print(\"Generated text:\", generated_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCAPtgtHind7",
        "outputId": "99c6085c-4019-4156-8cf0-c47ed4808674"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "\u001b[1m1641221/1641221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "Generated text: the movie was the the ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate GRU model\n",
        "gru_loss, gru_accuracy = gru_model.evaluate(x_test, y_test)\n",
        "print(f\"GRU Model Accuracy: {gru_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Yw9kZ_Minke",
        "outputId": "9076b846-e359-4d6c-9dbd-1abcb4dfbc2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - accuracy: 0.6894 - loss: 0.6399\n",
            "GRU Model Accuracy: 0.6894\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import LSTM\n",
        "\n",
        "# Build the LSTM model\n",
        "lstm_model = Sequential()\n",
        "lstm_model.add(Embedding(input_dim=max_features, output_dim=embedding_dim, input_length=maxlen))\n",
        "lstm_model.add(LSTM(gru_units, dropout=0.2, recurrent_dropout=0.2))\n",
        "lstm_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the LSTM model\n",
        "lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the LSTM model\n",
        "lstm_history = lstm_model.fit(x_train, y_train, batch_size=32, epochs=5, validation_split=0.2)\n",
        "\n",
        "# Evaluate LSTM model\n",
        "lstm_loss, lstm_accuracy = lstm_model.evaluate(x_test, y_test)\n",
        "print(f\"LSTM Model Accuracy: {lstm_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJejqSQTinna",
        "outputId": "c9186029-bf3f-448e-c9cc-0263e71f2a00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 95ms/step - accuracy: 0.7058 - loss: 0.5517 - val_accuracy: 0.8064 - val_loss: 0.4269\n",
            "Epoch 2/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 94ms/step - accuracy: 0.8801 - loss: 0.3011 - val_accuracy: 0.8380 - val_loss: 0.3797\n",
            "Epoch 3/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 96ms/step - accuracy: 0.9193 - loss: 0.2158 - val_accuracy: 0.8370 - val_loss: 0.4243\n",
            "Epoch 4/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 97ms/step - accuracy: 0.9367 - loss: 0.1691 - val_accuracy: 0.8246 - val_loss: 0.4258\n",
            "Epoch 5/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 93ms/step - accuracy: 0.9561 - loss: 0.1237 - val_accuracy: 0.8256 - val_loss: 0.5126\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 20ms/step - accuracy: 0.8219 - loss: 0.5154\n",
            "LSTM Model Accuracy: 0.8243\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"GRU Model Accuracy: {gru_accuracy:.4f}\")\n",
        "print(f\"LSTM Model Accuracy: {lstm_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtKy6wWtiyp1",
        "outputId": "43ff8284-8e15-4f40-8cb7-3212aed9c177"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GRU Model Accuracy: 0.6894\n",
            "LSTM Model Accuracy: 0.8243\n"
          ]
        }
      ]
    }
  ]
}